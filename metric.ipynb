{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPbAOernth5o0HNI5TiEPzV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["Project_Root = '/gdrive/MyDrive/CV_Project/'\n","from google.colab import drive\n","drive.mount('/gdrive')\n","%cd -q $Project_Root"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mn3mIsQxymU4","executionInfo":{"status":"ok","timestamp":1765587464498,"user_tz":300,"elapsed":971,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"d7461cc7-0aa4-4a80-d12e-af327f54cc79"},"execution_count":120,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oYEugKsOyosy","executionInfo":{"status":"ok","timestamp":1765580828758,"user_tz":300,"elapsed":711,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"56293871-5fdc-4ddb-8ece-86c779484e00"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["checkpoints\t\t     metric.ipynb\t train_pixelCNN\n","data\t\t\t     models\t\t train_vae.ipynb\n","documents\t\t     __pycache__\t train_vqvae.ipynb\n","GetData.ipynb\t\t     README.md\t\t utils.py\n","hierachical_vae_train.ipynb  requirements.txt\t visualization.py\n","hierarchical_train_pixelCNN  residualDataset.py  visualize.ipynb\n","images\t\t\t     train_hrvae.ipynb\n"]}]},{"cell_type":"code","execution_count":70,"metadata":{"id":"ecwyhZ5jsizG","executionInfo":{"status":"ok","timestamp":1765584197246,"user_tz":300,"elapsed":10,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.datasets as datasets\n","from skimage import data, img_as_float\n","from skimage.metrics import structural_similarity as ssim\n","from skimage.metrics import mean_squared_error\n","import os\n","from tqdm import tqdm\n","from models.vae import VanillaVAE"]},{"cell_type":"code","source":["BATCH_SIZE = 64\n","transform = torchvision.transforms.ToTensor()\n","\n","data_dir = './data'\n","\n","mnist_testset = datasets.MNIST(root=data_dir, train=False, download=False, transform=transform)\n","testloader = torch.utils.data.DataLoader(mnist_testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n","print(len(mnist_testset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s5k0RXKyyxor","executionInfo":{"status":"ok","timestamp":1765586585575,"user_tz":300,"elapsed":58,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"b6f22c1d-1865-4801-ab17-51384a5b318c"},"execution_count":106,"outputs":[{"output_type":"stream","name":"stdout","text":["10000\n"]}]},{"cell_type":"code","source":["class Config:\n","    # --- Paths ---\n","    WEIGHT_PATH = \"checkpoints/save_3_best.pth\"\n","    DATA_DIR = \"./data\"\n","    OUTPUT_DIR = \"./checkpoints\"\n","\n","    # --- Training Hyperparameters ---\n","    DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","    BATCH_SIZE = 64\n","    LEARNING_RATE = 1e-4\n","    NUM_EPOCHS = 10\n","    LOG_INTERVAL = 100\n","\n","    # --- Model Configuration ---\n","    NUM_HIERARCHY_LAYERS = 2\n","\n","    # --- Loss Weights (Adjust to tune training) ---\n","    LOSS_WEIGHT_SMOOTHNESS = 1.0\n","    LOSS_WEIGHT_RESIDUAL = 0.1\n","\n","class ResidualLatentUNet(nn.Module):\n","    def __init__(self, model_container, device=\"cpu\", num_layers=2):\n","        super().__init__()\n","        self.device = torch.device(device)\n","        self.fullvae = model_container.getFullVAE().to(self.device)\n","        self.fullvae.eval()\n","\n","        # Freeze VAE parameters\n","        for param in self.fullvae.parameters():\n","            param.requires_grad = False\n","\n","        # Get latent dimensions from VAE instance\n","        with torch.no_grad():\n","            dummy = torch.zeros(1, 1, 28, 28, device=self.device)\n","            zq, *_ = self.fullvae.quantize(dummy)\n","            _, latent_ch, latent_h, latent_w = zq.shape\n","\n","        in_ch = latent_ch * 2  # concatenated (image + residual)\n","        print(f\"  U-Net Input Latent Size: {latent_h}x{latent_w}, {in_ch} channels\")\n","\n","        # --- Encoder Path (Compression) ---\n","        # Enc1: 7x7 -> 4x4 (Skip 1)\n","        self.enc1 = nn.Sequential(\n","            nn.Conv2d(in_ch, 256, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(2, 2)\n","        )\n","\n","        # Enc2: 4x4 -> 2x2 (Skip 2)\n","        self.enc2 = nn.Sequential(\n","            nn.Conv2d(256, 512, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(2, 2)\n","        )\n","\n","        # --- Bottleneck ---\n","        self.bottleneck = nn.Sequential(\n","            nn.Conv2d(512, 1024, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(1024, 512, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","        # --- Decoder Path (Decompression & Skip) ---\n","\n","        # Dec2 (Innermost): Upsample (512ch) + Skip (512ch) -> 256ch\n","        self.up2 = nn.ConvTranspose2d(512, 512, 2, stride=2)\n","        self.dec2 = nn.Sequential(\n","            nn.Conv2d(512 + 512, 256, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","        # Dec1 (Outermost): Upsample (256ch) + Skip (256ch) -> 128ch\n","        self.up1 = nn.ConvTranspose2d(256, 256, 2, stride=2)\n","        self.dec1 = nn.Sequential(\n","            nn.Conv2d(256 + 256, 128, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 128, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","        # Final projection: 128ch -> 128ch (in_ch)\n","        self.final = nn.Conv2d(128, in_ch, 1)\n","\n","    def forward(self, img_tensor):\n","        img_tensor = img_tensor.to(self.device)\n","\n","        with torch.no_grad():\n","            # Get VAE latents and reconstruction\n","            zq_img, *_ = self.fullvae.quantize(img_tensor)\n","            recon = self.fullvae.decoder(zq_img)\n","            residual = img_tensor - recon\n","\n","            # Get residual latent\n","            zq_res, *_ = self.fullvae.quantize(residual)\n","\n","            # Align spatial dims (Safety check, should match)\n","            if zq_img.shape[-2:] != zq_res.shape[-2:]:\n","                zq_res = F.interpolate(zq_res, size=zq_img.shape[-2:], mode='nearest')\n","\n","        # U-Net Input (7x7, 128ch)\n","        z_concat = torch.cat([zq_img, zq_res], dim=1)\n","\n","        # Encoder path\n","        e1 = self.enc1(z_concat)    # Skip 1 (e1, expected 4x4)\n","        e2 = self.enc2(e1)          # Skip 2 (e2, expected 2x2)\n","\n","        # Bottleneck\n","        b = self.bottleneck(e2)     # (expected 2x2)\n","\n","        # Decoder 2 (Skip: e2)\n","        d2_up = self.up2(b)         # Upconvolution (expected 4x4)\n","\n","        # Interpolation check for Dec 2: Target size is e2.shape (expected 2x2)\n","        if d2_up.shape[2:] != e2.shape[2:]:\n","            # Resize upsampled feature to match the skip connection\n","            d2_up = F.interpolate(d2_up, size=e2.shape[2:], mode='nearest')\n","        d2 = self.dec2(torch.cat([d2_up, e2], dim=1))\n","\n","        # Decoder 1 (Skip: e1)\n","        d1_up = self.up1(d2)        # Upconvolution (expected 8x8 or 6x6)\n","\n","        # Interpolation check for Dec 1: Target size is z_concat.shape (expected 7x7)\n","        if d1_up.shape[2:] != z_concat.shape[2:]:\n","            d1_up = F.interpolate(d1_up, size=z_concat.shape[2:], mode='nearest') # This forces d1_up to 7x7\n","\n","        # --- FIX: SPATIAL MISMATCH RESOLUTION ---\n","        # The error occurs because e1 (e.g., 4x4 or 3x3) does not match d1_up (7x7).\n","        # We must resize e1 to match the target size of d1_up (which is 7x7).\n","        if d1_up.shape[2:] != e1.shape[2:]:\n","            e1_resized = F.interpolate(e1, size=d1_up.shape[2:], mode='nearest')\n","        else:\n","            e1_resized = e1\n","        # ----------------------------------------\n","\n","        d1 = self.dec1(torch.cat([d1_up, e1_resized], dim=1))\n","\n","        # Final projection\n","        z_refined = self.final(d1)\n","\n","        return {\n","            \"z_image\": zq_img,\n","            \"z_residual\": zq_res,\n","            \"z_concat\": z_concat,\n","            \"z_refined\": z_refined,\n","            \"recon\": recon,\n","            \"residual\": residual,\n","        }"],"metadata":{"id":"ESv6s9VPzjMZ","executionInfo":{"status":"ok","timestamp":1765580848739,"user_tz":300,"elapsed":71,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from models.vqvae import VQVAE\n","from models.decompose import DecomposeVAE"],"metadata":{"id":"EvOjVZmozOgB","executionInfo":{"status":"ok","timestamp":1765580852385,"user_tz":300,"elapsed":3643,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["image_vae_path = \"checkpoints/save_3_best.pth\"\n","device = \"cuda:0\"\n","\n","model_container = DecomposeVAE(weight_path=image_vae_path, device = device) # this runs in the datsaet so should be on cpu\n","fullvae = model_container.getFullVAE()"],"metadata":{"id":"gLAnoNuvz3NV","executionInfo":{"status":"ok","timestamp":1765580854107,"user_tz":300,"elapsed":1718,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["## Hierarchical Residual VAE\n","config = Config()\n","model_container = DecomposeVAE(config.WEIGHT_PATH, config.DEVICE)\n","hrvae = ResidualLatentUNet(model_container=model_container, device=config.DEVICE).to(config.DEVICE)\n","state_dict= torch.load(\"checkpoints/final_model.pth\")[\"model_state_dict\"]\n","hrvae.load_state_dict(state_dict)\n","hrvae.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OIQ5w_WQzvVA","executionInfo":{"status":"ok","timestamp":1765583561689,"user_tz":300,"elapsed":1190,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"bfab99b4-2335-4c15-a503-b5993f42f58a"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["  U-Net Input Latent Size: 7x7, 128 channels\n"]},{"output_type":"execute_result","data":{"text/plain":["ResidualLatentUNet(\n","  (fullvae): VQVAE(\n","    (encoder): Encoder(\n","      (conv): Sequential(\n","        (down0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","        (relu0): ReLU()\n","        (down1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","        (relu1): ReLU()\n","        (final_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","      (residual_stack): ResidualStack(\n","        (layers): ModuleList(\n","          (0-1): 2 x Sequential(\n","            (0): ReLU()\n","            (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (2): ReLU()\n","            (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          )\n","        )\n","      )\n","    )\n","    (pre_vq_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","    (vq): VectorQuantizer(\n","      (N_i_ts): SonnetExponentialMovingAverage()\n","      (m_i_ts): SonnetExponentialMovingAverage()\n","    )\n","    (decoder): Decoder(\n","      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (residual_stack): ResidualStack(\n","        (layers): ModuleList(\n","          (0-1): 2 x Sequential(\n","            (0): ReLU()\n","            (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (2): ReLU()\n","            (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          )\n","        )\n","      )\n","      (upconv): Sequential(\n","        (up0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","        (relu0): ReLU()\n","        (up1): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      )\n","    )\n","  )\n","  (enc1): Sequential(\n","    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (enc2): Sequential(\n","    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (bottleneck): Sequential(\n","    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","  )\n","  (up2): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n","  (dec2): Sequential(\n","    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","  )\n","  (up1): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","  (dec1): Sequential(\n","    (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","  )\n","  (final): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",")"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["checkpoint = torch.load(\"checkpoints/vae_save1_best.pth\")\n","vae = VanillaVAE(in_channels = 1, latent_dim = 128).to(device)\n","vae.load_state_dict(checkpoint[\"model_state_dict\"])\n","vae.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PhKWOdgUAJsj","executionInfo":{"status":"ok","timestamp":1765584324420,"user_tz":300,"elapsed":280,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"7b411e22-124f-48e1-bc74-825ccd192bd1"},"execution_count":75,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VanillaVAE(\n","  (encoder): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","    )\n","    (1): Sequential(\n","      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","    )\n","    (2): Sequential(\n","      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","    )\n","    (3): Sequential(\n","      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","    )\n","  )\n","  (fc_mu): Linear(in_features=1024, out_features=128, bias=True)\n","  (fc_var): Linear(in_features=1024, out_features=128, bias=True)\n","  (decoder_input): Linear(in_features=128, out_features=1024, bias=True)\n","  (decoder): Sequential(\n","    (0): Sequential(\n","      (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","    )\n","    (1): Sequential(\n","      (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","    )\n","    (2): Sequential(\n","      (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","    )\n","  )\n","  (final_layer): Sequential(\n","    (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): LeakyReLU(negative_slope=0.01)\n","    (3): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4): Tanh()\n","  )\n",")"]},"metadata":{},"execution_count":75}]},{"cell_type":"markdown","source":["### Reconstruction Metrics"],"metadata":{"id":"n7TLM4ymHyhy"}},{"cell_type":"code","source":["from skimage.metrics import peak_signal_noise_ratio as psnr"],"metadata":{"id":"sVfesLHN9bW3","executionInfo":{"status":"ok","timestamp":1765583216925,"user_tz":300,"elapsed":11,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["def metrics(model, testloader, device=\"cuda:0\"):\n","    mse_hist = []\n","    ssim_hist = []\n","    psnr_hist = []\n","\n","    for item in tqdm(testloader):\n","        img, label = item\n","\n","        if model == \"VQ-VAE\":\n","            pred = fullvae(img.to(device))[\"x_recon\"]\n","        elif model == \"VAE\":\n","            pred, _, mu, logvar = vae(img.to(device))\n","        else:\n","            pred = hrvae(img.to(device))[\"recon\"]\n","\n","        pred_numpy = pred.cpu().detach().squeeze().numpy()\n","        img_numpy = img.squeeze().numpy()\n","\n","        mse = mean_squared_error(img_numpy.reshape(-1), pred_numpy.reshape(-1))\n","        mse_hist.append(mse)\n","\n","        batch_ssim = []\n","        batch_psnr = []\n","        for i in range(len(img)):\n","            ssim_val = ssim(img_numpy[i], pred_numpy[i],\n","                          data_range=1.0,\n","                          win_size=7,\n","                          gaussian_weights=True)\n","            batch_ssim.append(ssim_val)\n","            batch_psnr.append(psnr(img_numpy[i], pred_numpy[i]))\n","\n","        ssim_hist.append(np.mean(batch_ssim))\n","        psnr_hist.append(np.mean(batch_psnr))\n","\n","    return mse_hist, ssim_hist, psnr_hist"],"metadata":{"id":"mlc9BAKu0ha4","executionInfo":{"status":"ok","timestamp":1765584619447,"user_tz":300,"elapsed":11,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["mse_hist, ssim_hist, psnr_hist = metrics(\"VQ-VAE\", testloader, device = \"cuda:0\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LUj24bav3plF","executionInfo":{"status":"ok","timestamp":1765584792897,"user_tz":300,"elapsed":56542,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"8106f12e-2e70-499e-e71d-fdc27c8a4575"},"execution_count":86,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10000/10000 [00:56<00:00, 176.96it/s]\n"]}]},{"cell_type":"code","source":["mse_mn1, mse_stdd1 = np.mean(mse_hist), np.std(mse_hist)\n","print(f\"MSE: {mse_mn1} +- {mse_stdd1}\")\n","ssim_mn1, ssim_stdd1 = np.mean(ssim_hist), np.std(ssim_hist)\n","print(f\"SSIM: {ssim_mn1} +- {ssim_stdd1}\")\n","psnr_mn1, psnr_stdd1 = np.mean(psnr_hist), np.std(psnr_hist)\n","print(f\"PSNR: {psnr_mn1} +- {psnr_stdd1}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IvG9yBdb4r8J","executionInfo":{"status":"ok","timestamp":1765584792909,"user_tz":300,"elapsed":5,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"3d8014a8-0930-40ad-9e6e-4fac24561692"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE: 0.0016477555109603325 +- 0.0007014837833603243\n","SSIM: 0.9558864325842032 +- 0.02242286187122203\n","PSNR: 50.47285651026326 +- 1.6234415458649374\n"]}]},{"cell_type":"code","source":["mse_hist1, ssim_hist1, psnr_hist1 = metrics(\"HR-VAE\", testloader, device = \"cuda:0\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nBA9QNGO-pCx","executionInfo":{"status":"ok","timestamp":1765584882382,"user_tz":300,"elapsed":89474,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"a938b5c7-2376-4209-f183-f700ae3837dc"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10000/10000 [01:29<00:00, 111.75it/s]\n"]}]},{"cell_type":"code","source":["mse_mn2, mse_stdd2 = np.mean(mse_hist1), np.std(mse_hist1)\n","print(f\"MSE: {mse_mn2} +- {mse_stdd2}\")\n","ssim_mn2, ssim_stdd2 = np.mean(ssim_hist1), np.std(ssim_hist1)\n","print(f\"SSIM: {ssim_mn2} +- {ssim_stdd2}\")\n","psnr_mn2, psnr_stdd2 = np.mean(psnr_hist1), np.std(psnr_hist1)\n","print(f\"PSNR: {psnr_mn2} +- {psnr_stdd2}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L0D0S7LH-23b","executionInfo":{"status":"ok","timestamp":1765584882448,"user_tz":300,"elapsed":60,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"5f1cdb6b-d6a1-42fc-f372-f37dd3f0c476"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE: 0.0014575542728746899 +- 0.0006315229046148367\n","SSIM: 0.95929028042509 +- 0.02058485633848428\n","PSNR: 50.70523145790703 +- 1.5850760627531841\n"]}]},{"cell_type":"code","source":["BATCH_SIZE = 1\n","transform = torchvision.transforms.Compose([\n","    torchvision.transforms.Pad(2),\n","    torchvision.transforms.ToTensor()\n","])\n","\n","data_dir = './data'\n","\n","mnist_testset = datasets.MNIST(root=data_dir, train=False, download=False, transform=transform)\n","testloader = torch.utils.data.DataLoader(mnist_testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n","print(len(mnist_testset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uKrMJf-XB2EV","executionInfo":{"status":"ok","timestamp":1765584378549,"user_tz":300,"elapsed":23,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"ef820925-be7a-4c55-de7c-e7fd1028f6dd"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["10000\n"]}]},{"cell_type":"code","source":["mse_hist2, ssim_hist2, psnr_hist2 = metrics(\"VAE\", testloader, device = \"cuda:0\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FWJ5I6AABl1u","executionInfo":{"status":"ok","timestamp":1765584673392,"user_tz":300,"elapsed":47400,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"10c9b982-6cc5-424c-f6c0-a16850b4253b"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10000/10000 [00:47<00:00, 210.89it/s]\n"]}]},{"cell_type":"code","source":["mse_mn3, mse_stdd3 = np.mean(mse_hist2), np.std(mse_hist2)\n","print(f\"MSE: {mse_mn3} +- {mse_stdd3}\")\n","ssim_mn3, ssim_stdd3 = np.mean(ssim_hist2), np.std(ssim_hist2)\n","print(f\"SSIM: {ssim_mn3} +- {ssim_stdd3}\")\n","psnr_mn3, psnr_stdd3 = np.mean(psnr_hist2), np.std(psnr_hist2)\n","print(f\"PSNR: {psnr_mn3} +- {psnr_stdd3}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3aGkMS2aB6pm","executionInfo":{"status":"ok","timestamp":1765584676047,"user_tz":300,"elapsed":13,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"0e62303c-7c4b-4c06-db99-98016ebecaa1"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE: 0.002700993245734508 +- 0.0011634623116972328\n","SSIM: 0.9462470612784327 +- 0.03392890303367568\n","PSNR: 48.941994357349536 +- 3.03701663739415\n"]}]},{"cell_type":"markdown","source":["### Generaton Metrics\n"],"metadata":{"id":"Mx1wflUZH1Lx"}},{"cell_type":"code","source":["!pip install torch-fidelity\n","!pip install prdc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"z-kQ_AgWHwys","executionInfo":{"status":"ok","timestamp":1765588466901,"user_tz":300,"elapsed":10469,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"c813a67f-0fb5-41d9-804e-2e3e10eff424"},"execution_count":136,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch-fidelity in /usr/local/lib/python3.12/dist-packages (0.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-fidelity) (2.0.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from torch-fidelity) (11.3.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-fidelity) (1.16.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from torch-fidelity) (2.9.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from torch-fidelity) (0.24.0+cu126)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-fidelity) (4.67.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (3.5.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->torch-fidelity) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->torch-fidelity) (3.0.3)\n","Collecting prdc\n","  Downloading prdc-0.2-py3-none-any.whl.metadata (8.7 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from prdc) (2.0.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from prdc) (1.6.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from prdc) (1.16.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from prdc) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->prdc) (3.6.0)\n","Downloading prdc-0.2-py3-none-any.whl (6.0 kB)\n","Installing collected packages: prdc\n","Successfully installed prdc-0.2\n"]}]},{"cell_type":"code","source":["from models.pixel_cnn import PixelCNN\n","from torch.autograd import Variable\n","from torchvision import transforms\n","from prdc import compute_prdc\n","import torch_fidelity\n","\n","net = PixelCNN(input_dim=1,hidden_dim=64,output_dim=512).to(device)\n","net.load_state_dict(torch.load(\"checkpoints/best_pixel_cnn.pth\"))\n","net.eval()\n","\n","codebook = model_container.getCodeBook()\n","decoder = model_container.getDecoder().eval()"],"metadata":{"collapsed":true,"id":"69FRW5nSIcLM","executionInfo":{"status":"ok","timestamp":1765588491136,"user_tz":300,"elapsed":712,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}}},"execution_count":138,"outputs":[]},{"cell_type":"code","source":["class VQVAEGenerator(torch.nn.Module):\n","    def __init__(self, net, codebook, decoder, device='cuda'):\n","        super().__init__()\n","        self.net = net\n","        self.codebook = codebook\n","        self.decoder = decoder\n","        self.device = device\n","\n","    def forward(self, batch_size = 64):\n","        num_gen = batch_size\n","        sample = torch.zeros(num_gen, 1, 7, 7, device=self.device)\n","        self.net.eval()\n","        with torch.no_grad():\n","            for i in range(7):\n","                for j in range(7):\n","                    out = self.net(Variable(sample))\n","                    probs = F.softmax(out[:, :, i, j], dim=1)\n","                    sample[:, :, i, j] = torch.multinomial(probs, 1).float()\n","\n","        sample_viewed = sample.view(sample.shape[0], -1).long()\n","        sample_after_codebook = self.codebook[:, sample_viewed]\n","        sample_after_codebook_reshape = sample_after_codebook.permute((1, 0, 2)).reshape(num_gen, 64, 7, 7)\n","        decoded_image = self.decoder(sample_after_codebook_reshape)\n","        return decoded_image\n","\n","generator = VQVAEGenerator(net, codebook, decoder, device=device)"],"metadata":{"id":"c2b40KV3Ixew","executionInfo":{"status":"ok","timestamp":1765588668627,"user_tz":300,"elapsed":8,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}}},"execution_count":146,"outputs":[]},{"cell_type":"code","source":["prec = []\n","recall = []\n","for real, _ in testloader:\n","  generated_image = generator()\n","\n","  real = (real - real.min()) / (real.max() - real.min())\n","  generated_image = (generated_image - generated_image.min()) / (generated_image.max() - generated_image.min())\n","\n","  real_flat = real.view(real.shape[0], -1).cpu().numpy()\n","  gen_flat = generated_image.view(generated_image.shape[0], -1).cpu().numpy()\n","\n","  prdc_metrics = compute_prdc(real_features=real_flat, fake_features=gen_flat, nearest_k=5)\n","  recall.append(prdc_metrics[\"precision\"].item())\n","  prec.append(prdc_metrics[\"recall\"].item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"1cKx9OTTRm2U","executionInfo":{"status":"ok","timestamp":1765588879680,"user_tz":300,"elapsed":45986,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"263ddf2f-f697-42fe-c47c-dd0fbebb07ea"},"execution_count":151,"outputs":[{"output_type":"stream","name":"stdout","text":["Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 64 Num fake: 64\n","Num real: 16 Num fake: 64\n","0.9716361464968153 0.12161624203821655\n","0.06276867153091269 0.06871738675594134\n"]}]},{"cell_type":"code","source":["print(np.mean(recall), np.mean(prec))\n","print(np.std(recall), np.std(prec))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jVt-sF8KTIR2","executionInfo":{"status":"ok","timestamp":1765588898490,"user_tz":300,"elapsed":17,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"cefab272-bb08-42d0-da9c-05c51f5843e4"},"execution_count":152,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9716361464968153 0.12161624203821655\n","0.06276867153091269 0.06871738675594134\n"]}]},{"cell_type":"code","source":["net1 = PixelCNN(input_dim=1,hidden_dim=64,output_dim=256).to(device)\n","net1.load_state_dict(torch.load(\"checkpoints/hier_best_pixel_cnn.pth\"))\n","net1.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"-HpzJWBXTd8l","executionInfo":{"status":"ok","timestamp":1765589019098,"user_tz":300,"elapsed":2608,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"12df022a-531c-4018-daaa-e02077fb8c0f"},"execution_count":153,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PixelCNN(\n","  (net): Sequential(\n","    (0): MaskedConv2d(1, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaskedConv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): MaskedConv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): ReLU(inplace=True)\n","    (9): MaskedConv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (11): ReLU(inplace=True)\n","    (12): MaskedConv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","    (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (14): ReLU(inplace=True)\n","    (15): MaskedConv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","    (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (17): ReLU(inplace=True)\n","    (18): MaskedConv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","    (19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (20): ReLU(inplace=True)\n","    (21): MaskedConv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","    (22): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (23): ReLU(inplace=True)\n","    (24): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","  )\n",")"]},"metadata":{},"execution_count":153}]},{"cell_type":"code","source":["def genHRVAE(batch_size = 64):\n","  num_gen = batch_size\n","  sample = torch.zeros(num_gen, 1, 28, 28).to(device)\n","  sample.fill_(0)\n","  net.train(False)\n","  with torch.no_grad():\n","    for i in range(28):\n","        for j in range(28):\n","            out = net1(Variable(sample, volatile=True))\n","            probs = F.softmax(out[:, :, i, j]).data\n","            sample[:, :, i, j] = torch.multinomial(probs, 1).float()\n","  return sample"],"metadata":{"id":"-Zm4ffmWTscV","executionInfo":{"status":"ok","timestamp":1765589123309,"user_tz":300,"elapsed":2,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}}},"execution_count":155,"outputs":[]},{"cell_type":"code","source":["prec1 = []\n","recall1 = []\n","for idx, (real, _) in enumerate(testloader):\n","  if(idx>10):\n","    continue\n","  generated_image = genHRVAE()\n","\n","  real = (real - real.min()) / (real.max() - real.min())\n","  generated_image = (generated_image - generated_image.min()) / (generated_image.max() - generated_image.min())\n","\n","  real_flat = real.view(real.shape[0], -1).cpu().numpy()\n","  gen_flat = generated_image.view(generated_image.shape[0], -1).cpu().numpy()\n","\n","  prdc_metrics = compute_prdc(real_features=real_flat, fake_features=gen_flat, nearest_k=5)\n","  recall1.append(prdc_metrics[\"precision\"].item())\n","  prec1.append(prdc_metrics[\"recall\"].item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M0i27Fw2TvsT","executionInfo":{"status":"ok","timestamp":1765589523787,"user_tz":300,"elapsed":189570,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"57a44878-c5d6-4026-d949-5488fc99378c"},"execution_count":158,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1381750579.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  out = net1(Variable(sample, volatile=True))\n","/tmp/ipython-input-1381750579.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(out[:, :, i, j]).data\n"]},{"output_type":"stream","name":"stdout","text":["Num real: 64 Num fake: 64\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1381750579.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  out = net1(Variable(sample, volatile=True))\n","/tmp/ipython-input-1381750579.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(out[:, :, i, j]).data\n"]},{"output_type":"stream","name":"stdout","text":["Num real: 64 Num fake: 64\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1381750579.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  out = net1(Variable(sample, volatile=True))\n","/tmp/ipython-input-1381750579.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(out[:, :, i, j]).data\n"]},{"output_type":"stream","name":"stdout","text":["Num real: 64 Num fake: 64\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1381750579.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  out = net1(Variable(sample, volatile=True))\n","/tmp/ipython-input-1381750579.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(out[:, :, i, j]).data\n"]},{"output_type":"stream","name":"stdout","text":["Num real: 64 Num fake: 64\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1381750579.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  out = net1(Variable(sample, volatile=True))\n","/tmp/ipython-input-1381750579.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(out[:, :, i, j]).data\n"]},{"output_type":"stream","name":"stdout","text":["Num real: 64 Num fake: 64\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1381750579.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  out = net1(Variable(sample, volatile=True))\n","/tmp/ipython-input-1381750579.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(out[:, :, i, j]).data\n"]},{"output_type":"stream","name":"stdout","text":["Num real: 64 Num fake: 64\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1381750579.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  out = net1(Variable(sample, volatile=True))\n","/tmp/ipython-input-1381750579.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(out[:, :, i, j]).data\n"]},{"output_type":"stream","name":"stdout","text":["Num real: 64 Num fake: 64\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1381750579.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  out = net1(Variable(sample, volatile=True))\n","/tmp/ipython-input-1381750579.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(out[:, :, i, j]).data\n"]},{"output_type":"stream","name":"stdout","text":["Num real: 64 Num fake: 64\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1381750579.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  out = net1(Variable(sample, volatile=True))\n","/tmp/ipython-input-1381750579.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(out[:, :, i, j]).data\n"]},{"output_type":"stream","name":"stdout","text":["Num real: 64 Num fake: 64\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1381750579.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  out = net1(Variable(sample, volatile=True))\n","/tmp/ipython-input-1381750579.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(out[:, :, i, j]).data\n"]},{"output_type":"stream","name":"stdout","text":["Num real: 64 Num fake: 64\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1381750579.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  out = net1(Variable(sample, volatile=True))\n","/tmp/ipython-input-1381750579.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(out[:, :, i, j]).data\n"]},{"output_type":"stream","name":"stdout","text":["Num real: 64 Num fake: 64\n"]}]},{"cell_type":"code","source":["print(np.mean(recall1), np.mean(prec1))\n","print(np.std(recall1), np.std(prec1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QOYZ4eB6UJh2","executionInfo":{"status":"ok","timestamp":1765589523796,"user_tz":300,"elapsed":6,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"5310566e-d893-4cbc-93b7-4caeddfb086c"},"execution_count":159,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9417613636363636 0.5625\n","0.04111964439241514 0.051607676490298154\n"]}]}]}