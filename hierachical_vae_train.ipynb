{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM8Sl+YZCeW4RTgJ2P0JUey"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Setup Environment"],"metadata":{"id":"IkdFdGlf6rIH"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"m7oWo4Wc6F55","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765479382075,"user_tz":300,"elapsed":542,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"34c8a0e3-6b41-4707-abb6-fdfeeb14bf9e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"]}],"source":["Project_Root = '/gdrive/MyDrive/CV_Project/'\n","from google.colab import drive\n","drive.mount('/gdrive')\n","%cd -q $Project_Root"]},{"cell_type":"code","source":["!ls"],"metadata":{"id":"QUzldT-x6u-F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765479382178,"user_tz":300,"elapsed":102,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"e9bdb60e-3fd3-4932-d0b0-f6b4d16bc5d7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["checkpoints\t\t     models\t\t train_pixelCNN\n","data\t\t\t     __pycache__\t train_vae.ipynb\n","documents\t\t     README.md\t\t train_vqvae.ipynb\n","GetData.ipynb\t\t     requirements.txt\t utils.py\n","hierachical_vae_train.ipynb  residualDataset.py  visualization.py\n","images\t\t\t     train_hrvae.ipynb\t visualize.ipynb\n"]}]},{"cell_type":"code","source":["# !pip install -r requirements.txt --upgrade"],"metadata":{"id":"UD7r2gcV6yda","executionInfo":{"status":"ok","timestamp":1765476256448,"user_tz":300,"elapsed":3,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["### Setup all the data and hyper-parameters"],"metadata":{"id":"5joal58h6ySG"}},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.datasets as datasets\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tqdm import tqdm"],"metadata":{"id":"UNVKnihl653T","executionInfo":{"status":"ok","timestamp":1765479393254,"user_tz":300,"elapsed":10747,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["data_dir = './data'\n","\n","BATCH_SIZE = 64\n","transform = torchvision.transforms.ToTensor()\n","\n","mnist_trainset = datasets.MNIST(root=data_dir, train=True, download=False, transform=transform)\n","trainloader = torch.utils.data.DataLoader(mnist_trainset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n","\n","mnist_testset = datasets.MNIST(root=data_dir, train=False, download=False, transform=transform)\n","testloader = torch.utils.data.DataLoader(mnist_testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n","print(len(mnist_testset))"],"metadata":{"id":"Cq_loKyb67pf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765479393430,"user_tz":300,"elapsed":168,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"0b211922-f00e-40ad-91c8-3a962337df27"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["10000\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.datasets as datasets\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","import os\n","\n","# Assuming these files are present in the environment\n","from models.decompose import DecomposeVAE\n","\n","class Config:\n","    # --- Paths ---\n","    WEIGHT_PATH = \"checkpoints/save_3_best.pth\"\n","    DATA_DIR = \"./data\"\n","    OUTPUT_DIR = \"./checkpoints\"\n","\n","    # --- Training Hyperparameters ---\n","    DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","    BATCH_SIZE = 64\n","    LEARNING_RATE = 1e-4\n","    NUM_EPOCHS = 10\n","    LOG_INTERVAL = 100\n","\n","    # --- Model Configuration ---\n","    NUM_HIERARCHY_LAYERS = 2\n","\n","    # --- Loss Weights (Adjust to tune training) ---\n","    LOSS_WEIGHT_SMOOTHNESS = 1.0\n","    LOSS_WEIGHT_RESIDUAL = 0.1\n","\n","class ResidualLatentUNet(nn.Module):\n","    def __init__(self, model_container, device=\"cpu\", num_layers=2):\n","        super().__init__()\n","        self.device = torch.device(device)\n","        self.fullvae = model_container.getFullVAE().to(self.device)\n","        self.fullvae.eval()\n","\n","        # Freeze VAE parameters\n","        for param in self.fullvae.parameters():\n","            param.requires_grad = False\n","\n","        # Get latent dimensions from VAE instance\n","        with torch.no_grad():\n","            dummy = torch.zeros(1, 1, 28, 28, device=self.device)\n","            zq, *_ = self.fullvae.quantize(dummy)\n","            _, latent_ch, latent_h, latent_w = zq.shape\n","\n","        in_ch = latent_ch * 2  # concatenated (image + residual)\n","        print(f\"  U-Net Input Latent Size: {latent_h}x{latent_w}, {in_ch} channels\")\n","\n","        # --- Encoder Path (Compression) ---\n","        # Enc1: 7x7 -> 4x4 (Skip 1)\n","        self.enc1 = nn.Sequential(\n","            nn.Conv2d(in_ch, 256, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(2, 2)\n","        )\n","\n","        # Enc2: 4x4 -> 2x2 (Skip 2)\n","        self.enc2 = nn.Sequential(\n","            nn.Conv2d(256, 512, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(2, 2)\n","        )\n","\n","        # --- Bottleneck ---\n","        self.bottleneck = nn.Sequential(\n","            nn.Conv2d(512, 1024, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(1024, 512, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","        # --- Decoder Path (Decompression & Skip) ---\n","\n","        # Dec2 (Innermost): Upsample (512ch) + Skip (512ch) -> 256ch\n","        self.up2 = nn.ConvTranspose2d(512, 512, 2, stride=2)\n","        self.dec2 = nn.Sequential(\n","            nn.Conv2d(512 + 512, 256, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","        # Dec1 (Outermost): Upsample (256ch) + Skip (256ch) -> 128ch\n","        self.up1 = nn.ConvTranspose2d(256, 256, 2, stride=2)\n","        self.dec1 = nn.Sequential(\n","            nn.Conv2d(256 + 256, 128, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 128, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","        # Final projection: 128ch -> 128ch (in_ch)\n","        self.final = nn.Conv2d(128, in_ch, 1)\n","\n","    def forward(self, img_tensor):\n","        img_tensor = img_tensor.to(self.device)\n","\n","        with torch.no_grad():\n","            # Get VAE latents and reconstruction\n","            zq_img, *_ = self.fullvae.quantize(img_tensor)\n","            recon = self.fullvae.decoder(zq_img)\n","            residual = img_tensor - recon\n","\n","            # Get residual latent\n","            zq_res, *_ = self.fullvae.quantize(residual)\n","\n","            # Align spatial dims (Safety check, should match)\n","            if zq_img.shape[-2:] != zq_res.shape[-2:]:\n","                zq_res = F.interpolate(zq_res, size=zq_img.shape[-2:], mode='nearest')\n","\n","        # U-Net Input (7x7, 128ch)\n","        z_concat = torch.cat([zq_img, zq_res], dim=1)\n","\n","        # Encoder path\n","        e1 = self.enc1(z_concat)    # Skip 1 (e1, expected 4x4)\n","        e2 = self.enc2(e1)          # Skip 2 (e2, expected 2x2)\n","\n","        # Bottleneck\n","        b = self.bottleneck(e2)     # (expected 2x2)\n","\n","        # Decoder 2 (Skip: e2)\n","        d2_up = self.up2(b)         # Upconvolution (expected 4x4)\n","\n","        # Interpolation check for Dec 2: Target size is e2.shape (expected 2x2)\n","        if d2_up.shape[2:] != e2.shape[2:]:\n","            # Resize upsampled feature to match the skip connection\n","            d2_up = F.interpolate(d2_up, size=e2.shape[2:], mode='nearest')\n","        d2 = self.dec2(torch.cat([d2_up, e2], dim=1))\n","\n","        # Decoder 1 (Skip: e1)\n","        d1_up = self.up1(d2)        # Upconvolution (expected 8x8 or 6x6)\n","\n","        # Interpolation check for Dec 1: Target size is z_concat.shape (expected 7x7)\n","        if d1_up.shape[2:] != z_concat.shape[2:]:\n","            d1_up = F.interpolate(d1_up, size=z_concat.shape[2:], mode='nearest') # This forces d1_up to 7x7\n","\n","        # --- FIX: SPATIAL MISMATCH RESOLUTION ---\n","        # The error occurs because e1 (e.g., 4x4 or 3x3) does not match d1_up (7x7).\n","        # We must resize e1 to match the target size of d1_up (which is 7x7).\n","        if d1_up.shape[2:] != e1.shape[2:]:\n","            e1_resized = F.interpolate(e1, size=d1_up.shape[2:], mode='nearest')\n","        else:\n","            e1_resized = e1\n","        # ----------------------------------------\n","\n","        d1 = self.dec1(torch.cat([d1_up, e1_resized], dim=1))\n","\n","        # Final projection\n","        z_refined = self.final(d1)\n","\n","        return {\n","            \"z_image\": zq_img,\n","            \"z_residual\": zq_res,\n","            \"z_concat\": z_concat,\n","            \"z_refined\": z_refined,\n","            \"recon\": recon,\n","            \"residual\": residual,\n","        }"],"metadata":{"id":"5EfioL7r6_jr","executionInfo":{"status":"ok","timestamp":1765479393512,"user_tz":300,"elapsed":76,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class HierarchicalLoss(nn.Module):\n","    def __init__(self, smoothness_weight, residual_weight):\n","        super().__init__()\n","        self.smoothness_weight = smoothness_weight\n","        self.residual_weight = residual_weight\n","\n","    def forward(self, unet_output, original_image):\n","        z_refined = unet_output[\"z_refined\"]\n","        z_concat = unet_output[\"z_concat\"]\n","        smoothness_loss = F.mse_loss(z_refined, z_concat)\n","\n","        z_residual = unet_output[\"z_residual\"]\n","        residual_energy_loss = torch.mean(z_residual ** 2)\n","\n","        total_loss = (self.smoothness_weight * smoothness_loss) + \\\n","                     (self.residual_weight * residual_energy_loss)\n","\n","        return total_loss, {\n","            \"total\": total_loss.item(),\n","            \"smoothness\": smoothness_loss.item(),\n","            \"residual\": residual_energy_loss.item(),\n","        }\n","\n","\n","# ==============================================================================\n","# 4. TRAINING AND UTILITY FUNCTIONS\n","# ==============================================================================\n","\n","def train_epoch(model, dataloader, criterion, optimizer, device, epoch):\n","    model.train()\n","    total_loss, total_smoothness, total_residual = 0, 0, 0\n","    pbar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{Config.NUM_EPOCHS}')\n","\n","    for batch_idx, (data, _) in enumerate(pbar):\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss, loss_dict = criterion(output, data)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss_dict['total']\n","        total_smoothness += loss_dict['smoothness']\n","        total_residual += loss_dict['residual']\n","\n","        if batch_idx % Config.LOG_INTERVAL == 0:\n","            pbar.set_postfix({\n","                'loss': f\"{loss_dict['total']:.4f}\",\n","                'smooth': f\"{loss_dict['smoothness']:.4f}\",\n","                'res_e': f\"{loss_dict['residual']:.4f}\"\n","            })\n","\n","    num_batches = len(dataloader)\n","    return {\n","        'total': total_loss / num_batches,\n","        'smoothness': total_smoothness / num_batches,\n","        'residual': total_residual / num_batches\n","    }\n","\n","\n","def validate(model, dataloader, criterion, device):\n","    model.eval()\n","    total_loss, total_smoothness, total_residual = 0, 0, 0\n","    with torch.no_grad():\n","        for data, _ in tqdm(dataloader, desc='Validating', leave=False):\n","            data = data.to(device)\n","            output = model(data)\n","            loss, loss_dict = criterion(output, data)\n","\n","            total_loss += loss_dict['total']\n","            total_smoothness += loss_dict['smoothness']\n","            total_residual += loss_dict['residual']\n","\n","    num_batches = len(dataloader)\n","    return {\n","        'total': total_loss / num_batches,\n","        'smoothness': total_smoothness / num_batches,\n","        'residual': total_residual / num_batches\n","    }"],"metadata":{"id":"-5kofdx8nrwN","executionInfo":{"status":"ok","timestamp":1765478414330,"user_tz":300,"elapsed":2,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, save_dir='checkpoints'):\n","    \"\"\"\n","    Complete training loop with validation and checkpoint saving\n","    \"\"\"\n","\n","    # Create save directory if it doesn't exist\n","    os.makedirs(save_dir, exist_ok=True)\n","\n","    # Initialize best loss tracking\n","    best_val_loss = float('inf')\n","    train_history = {'train': [], 'val': []}\n","\n","    # Training loop\n","    for epoch in range(num_epochs):\n","        print(f\"\\n{'='*60}\")\n","        print(f\"Epoch {epoch+1}/{num_epochs}\")\n","        print(f\"{'='*60}\")\n","\n","        # Train for one epoch\n","        train_metrics = train_epoch(\n","            model=model,\n","            dataloader=train_loader,\n","            criterion=criterion,\n","            optimizer=optimizer,\n","            device=device,\n","            epoch=epoch\n","        )\n","\n","        # Validate\n","        val_metrics = validate(\n","            model=model,\n","            dataloader=val_loader,\n","            criterion=criterion,\n","            device=device\n","        )\n","\n","        # Store history\n","        train_history['train'].append(train_metrics)\n","        train_history['val'].append(val_metrics)\n","\n","        # Print epoch summary\n","        print(f\"\\nEpoch {epoch+1} Summary:\")\n","        print(f\"  Train - Total: {train_metrics['total']:.6f}, \"\n","              f\"Smoothness: {train_metrics['smoothness']:.6f}, \"\n","              f\"Residual: {train_metrics['residual']:.6f}\")\n","        print(f\"  Val   - Total: {val_metrics['total']:.6f}, \"\n","              f\"Smoothness: {val_metrics['smoothness']:.6f}, \"\n","              f\"Residual: {val_metrics['residual']:.6f}\")\n","\n","        # Save best model\n","        if val_metrics['total'] < best_val_loss:\n","            best_val_loss = val_metrics['total']\n","            torch.save({\n","                'epoch': epoch + 1,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'train_metrics': train_metrics,\n","                'val_metrics': val_metrics,\n","                'best_val_loss': best_val_loss,\n","            }, os.path.join(save_dir, 'best_model.pth'))\n","            print(f\"  ✓ Saved best model with val loss: {best_val_loss:.6f}\")\n","\n","        # Save regular checkpoint (every 10 epochs or adjust as needed)\n","        if (epoch + 1) % 10 == 0:\n","            torch.save({\n","                'epoch': epoch + 1,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'train_history': train_history,\n","            }, os.path.join(save_dir, f'checkpoint_epoch_{epoch+1}.pth'))\n","            print(f\"  ✓ Saved checkpoint at epoch {epoch+1}\")\n","\n","    # Save final model\n","    torch.save({\n","        'epoch': num_epochs,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'train_history': train_history,\n","        'final_val_loss': val_metrics['total'],\n","    }, os.path.join(save_dir, 'final_model.pth'))\n","\n","    print(f\"\\n{'='*60}\")\n","    print(\"Training completed!\")\n","    print(f\"Best validation loss: {best_val_loss:.6f}\")\n","    print(f\"{'='*60}\")\n","\n","    return model, train_history"],"metadata":{"id":"PKHZg-Ljn_9c","executionInfo":{"status":"ok","timestamp":1765478417876,"user_tz":300,"elapsed":3,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["config = Config()\n","model_container = DecomposeVAE(config.WEIGHT_PATH, config.DEVICE)\n","model = ResidualLatentUNet(model_container=model_container, device=config.DEVICE).to(config.DEVICE)\n","train_params = [params for params in model.parameters()]\n","optimizer = torch.optim.Adam(train_params, lr=config.LEARNING_RATE)\n","criterion = HierarchicalLoss(smoothness_weight=config.LOSS_WEIGHT_SMOOTHNESS, residual_weight=config.LOSS_WEIGHT_RESIDUAL)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZCgoQfvMpX5X","executionInfo":{"status":"ok","timestamp":1765478420062,"user_tz":300,"elapsed":199,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"aa31cca8-415f-4b6b-98a8-b8d80a5cb8f8"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["  U-Net Input Latent Size: 7x7, 128 channels\n"]}]},{"cell_type":"code","source":["train_model(model, trainloader, testloader, criterion, optimizer, config.DEVICE, config.NUM_EPOCHS, save_dir='checkpoints')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T2d2roBtpyuj","executionInfo":{"status":"ok","timestamp":1765478883534,"user_tz":300,"elapsed":460367,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"881cda96-d016-4c56-d6e7-892d43877dad"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","Epoch 1/10\n","============================================================\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/10: 100%|██████████| 938/938 [00:43<00:00, 21.68it/s, loss=0.0861, smooth=0.0723, res_e=0.1373]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1 Summary:\n","  Train - Total: 0.204569, Smoothness: 0.190549, Residual: 0.140207\n","  Val   - Total: 0.087627, Smoothness: 0.073557, Residual: 0.140692\n","  ✓ Saved best model with val loss: 0.087627\n","\n","============================================================\n","Epoch 2/10\n","============================================================\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/10: 100%|██████████| 938/938 [00:41<00:00, 22.72it/s, loss=0.0581, smooth=0.0443, res_e=0.1375]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 2 Summary:\n","  Train - Total: 0.069092, Smoothness: 0.055094, Residual: 0.139979\n","  Val   - Total: 0.061541, Smoothness: 0.047521, Residual: 0.140198\n","  ✓ Saved best model with val loss: 0.061541\n","\n","============================================================\n","Epoch 3/10\n","============================================================\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/10: 100%|██████████| 938/938 [00:42<00:00, 21.87it/s, loss=0.0475, smooth=0.0339, res_e=0.1369]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 3 Summary:\n","  Train - Total: 0.052538, Smoothness: 0.038560, Residual: 0.139782\n","  Val   - Total: 0.049551, Smoothness: 0.035529, Residual: 0.140223\n","  ✓ Saved best model with val loss: 0.049551\n","\n","============================================================\n","Epoch 4/10\n","============================================================\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/10: 100%|██████████| 938/938 [00:43<00:00, 21.67it/s, loss=0.0404, smooth=0.0269, res_e=0.1355]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 4 Summary:\n","  Train - Total: 0.044218, Smoothness: 0.030244, Residual: 0.139743\n","  Val   - Total: 0.042053, Smoothness: 0.028031, Residual: 0.140222\n","  ✓ Saved best model with val loss: 0.042053\n","\n","============================================================\n","Epoch 5/10\n","============================================================\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/10: 100%|██████████| 938/938 [00:42<00:00, 21.93it/s, loss=0.0361, smooth=0.0224, res_e=0.1363]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 5 Summary:\n","  Train - Total: 0.038943, Smoothness: 0.024963, Residual: 0.139794\n","  Val   - Total: 0.037010, Smoothness: 0.022993, Residual: 0.140171\n","  ✓ Saved best model with val loss: 0.037010\n","\n","============================================================\n","Epoch 6/10\n","============================================================\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/10: 100%|██████████| 938/938 [00:42<00:00, 21.97it/s, loss=0.0328, smooth=0.0191, res_e=0.1365]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 6 Summary:\n","  Train - Total: 0.035175, Smoothness: 0.021207, Residual: 0.139683\n","  Val   - Total: 0.035540, Smoothness: 0.021529, Residual: 0.140108\n","  ✓ Saved best model with val loss: 0.035540\n","\n","============================================================\n","Epoch 7/10\n","============================================================\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/10: 100%|██████████| 938/938 [00:42<00:00, 22.21it/s, loss=0.0296, smooth=0.0161, res_e=0.1355]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 7 Summary:\n","  Train - Total: 0.032286, Smoothness: 0.018328, Residual: 0.139583\n","  Val   - Total: 0.032282, Smoothness: 0.018280, Residual: 0.140015\n","  ✓ Saved best model with val loss: 0.032282\n","\n","============================================================\n","Epoch 8/10\n","============================================================\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/10: 100%|██████████| 938/938 [00:42<00:00, 21.93it/s, loss=0.0280, smooth=0.0143, res_e=0.1373]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 8 Summary:\n","  Train - Total: 0.030002, Smoothness: 0.016050, Residual: 0.139523\n","  Val   - Total: 0.030066, Smoothness: 0.016062, Residual: 0.140033\n","  ✓ Saved best model with val loss: 0.030066\n","\n","============================================================\n","Epoch 9/10\n","============================================================\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/10: 100%|██████████| 938/938 [00:42<00:00, 22.21it/s, loss=0.0263, smooth=0.0127, res_e=0.1358]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 9 Summary:\n","  Train - Total: 0.028121, Smoothness: 0.014173, Residual: 0.139476\n","  Val   - Total: 0.028044, Smoothness: 0.014041, Residual: 0.140022\n","  ✓ Saved best model with val loss: 0.028044\n","\n","============================================================\n","Epoch 10/10\n","============================================================\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/10: 100%|██████████| 938/938 [00:41<00:00, 22.37it/s, loss=0.0257, smooth=0.0119, res_e=0.1381]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 10 Summary:\n","  Train - Total: 0.026649, Smoothness: 0.012705, Residual: 0.139438\n","  Val   - Total: 0.028349, Smoothness: 0.014352, Residual: 0.139966\n","  ✓ Saved checkpoint at epoch 10\n","\n","============================================================\n","Training completed!\n","Best validation loss: 0.028044\n","============================================================\n"]},{"output_type":"execute_result","data":{"text/plain":["(ResidualLatentUNet(\n","   (fullvae): VQVAE(\n","     (encoder): Encoder(\n","       (conv): Sequential(\n","         (down0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","         (relu0): ReLU()\n","         (down1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","         (relu1): ReLU()\n","         (final_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","       )\n","       (residual_stack): ResidualStack(\n","         (layers): ModuleList(\n","           (0-1): 2 x Sequential(\n","             (0): ReLU()\n","             (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","             (2): ReLU()\n","             (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","           )\n","         )\n","       )\n","     )\n","     (pre_vq_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","     (vq): VectorQuantizer(\n","       (N_i_ts): SonnetExponentialMovingAverage()\n","       (m_i_ts): SonnetExponentialMovingAverage()\n","     )\n","     (decoder): Decoder(\n","       (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","       (residual_stack): ResidualStack(\n","         (layers): ModuleList(\n","           (0-1): 2 x Sequential(\n","             (0): ReLU()\n","             (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","             (2): ReLU()\n","             (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","           )\n","         )\n","       )\n","       (upconv): Sequential(\n","         (up0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","         (relu0): ReLU()\n","         (up1): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","       )\n","     )\n","   )\n","   (enc1): Sequential(\n","     (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","     (1): ReLU(inplace=True)\n","     (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","     (3): ReLU(inplace=True)\n","     (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","   )\n","   (enc2): Sequential(\n","     (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","     (1): ReLU(inplace=True)\n","     (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","     (3): ReLU(inplace=True)\n","     (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","   )\n","   (bottleneck): Sequential(\n","     (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","     (1): ReLU(inplace=True)\n","     (2): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","     (3): ReLU(inplace=True)\n","   )\n","   (up2): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n","   (dec2): Sequential(\n","     (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","     (1): ReLU(inplace=True)\n","     (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","     (3): ReLU(inplace=True)\n","   )\n","   (up1): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","   (dec1): Sequential(\n","     (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","     (1): ReLU(inplace=True)\n","     (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","     (3): ReLU(inplace=True)\n","   )\n","   (final): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n"," ),\n"," {'train': [{'total': 0.2045692921256714,\n","    'smoothness': 0.19054863898993046,\n","    'residual': 0.14020653045190168},\n","   {'total': 0.06909239021286781,\n","    'smoothness': 0.05509449674614838,\n","    'residual': 0.1399789336107687},\n","   {'total': 0.052538103441884525,\n","    'smoothness': 0.03855992632229,\n","    'residual': 0.1397817666564923},\n","   {'total': 0.04421842974354463,\n","    'smoothness': 0.030244090266700493,\n","    'residual': 0.13974339195660182},\n","   {'total': 0.038942563444820805,\n","    'smoothness': 0.024963206659231994,\n","    'residual': 0.13979356596147074},\n","   {'total': 0.035175360645900274,\n","    'smoothness': 0.02120701136039709,\n","    'residual': 0.1396834908613264},\n","   {'total': 0.0322864489125481,\n","    'smoothness': 0.018328185512948392,\n","    'residual': 0.13958263241533023},\n","   {'total': 0.03000200738800741,\n","    'smoothness': 0.016049675126152952,\n","    'residual': 0.13952332036073273},\n","   {'total': 0.02812102369702002,\n","    'smoothness': 0.01417338770272127,\n","    'residual': 0.13947635835040606},\n","   {'total': 0.02664853834600718,\n","    'smoothness': 0.012704720669018942,\n","    'residual': 0.1394381747444047}],\n","  'val': [{'total': 0.08762656527150209,\n","    'smoothness': 0.07355741494495398,\n","    'residual': 0.1406915071094112},\n","   {'total': 0.06154067311317298,\n","    'smoothness': 0.04752084840634826,\n","    'residual': 0.14019824488527455},\n","   {'total': 0.04955144425865951,\n","    'smoothness': 0.03552913872204769,\n","    'residual': 0.14022305133236443},\n","   {'total': 0.04205326690890227,\n","    'smoothness': 0.02803109347772826,\n","    'residual': 0.140221731108465},\n","   {'total': 0.03701043349637347,\n","    'smoothness': 0.02299332472786402,\n","    'residual': 0.1401710852885702},\n","   {'total': 0.03553992255952707,\n","    'smoothness': 0.02152908206650406,\n","    'residual': 0.14010840265234564},\n","   {'total': 0.03228163190043656,\n","    'smoothness': 0.01828008957776674,\n","    'residual': 0.1400154217792924},\n","   {'total': 0.030065816892370298,\n","    'smoothness': 0.01606246843269676,\n","    'residual': 0.14003348217648307},\n","   {'total': 0.028043511199059002,\n","    'smoothness': 0.01404135205017723,\n","    'residual': 0.14002158943634885},\n","   {'total': 0.028349045035281,\n","    'smoothness': 0.014352399149945207,\n","    'residual': 0.13996645646869757}]})"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["from utils import save_img_tensors_as_grid, plot_image_batch"],"metadata":{"id":"k7xRkN5o7EX3","executionInfo":{"status":"ok","timestamp":1765479393515,"user_tz":300,"elapsed":2,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["config = Config()\n","model_container = DecomposeVAE(config.WEIGHT_PATH, config.DEVICE)\n","model = ResidualLatentUNet(model_container=model_container, device=config.DEVICE).to(config.DEVICE)\n","state_dict= torch.load(\"checkpoints/final_model.pth\")[\"model_state_dict\"]\n","model.load_state_dict(state_dict)\n","model.eval()"],"metadata":{"id":"uSHE2LowCTH-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765479495027,"user_tz":300,"elapsed":597,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"09736402-deaa-4a3d-a9a6-8d6bc0207b7a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["  U-Net Input Latent Size: 7x7, 128 channels\n"]},{"output_type":"execute_result","data":{"text/plain":["ResidualLatentUNet(\n","  (fullvae): VQVAE(\n","    (encoder): Encoder(\n","      (conv): Sequential(\n","        (down0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","        (relu0): ReLU()\n","        (down1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","        (relu1): ReLU()\n","        (final_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","      (residual_stack): ResidualStack(\n","        (layers): ModuleList(\n","          (0-1): 2 x Sequential(\n","            (0): ReLU()\n","            (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (2): ReLU()\n","            (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          )\n","        )\n","      )\n","    )\n","    (pre_vq_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","    (vq): VectorQuantizer(\n","      (N_i_ts): SonnetExponentialMovingAverage()\n","      (m_i_ts): SonnetExponentialMovingAverage()\n","    )\n","    (decoder): Decoder(\n","      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (residual_stack): ResidualStack(\n","        (layers): ModuleList(\n","          (0-1): 2 x Sequential(\n","            (0): ReLU()\n","            (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (2): ReLU()\n","            (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          )\n","        )\n","      )\n","      (upconv): Sequential(\n","        (up0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","        (relu0): ReLU()\n","        (up1): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      )\n","    )\n","  )\n","  (enc1): Sequential(\n","    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (enc2): Sequential(\n","    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (bottleneck): Sequential(\n","    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","  )\n","  (up2): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n","  (dec2): Sequential(\n","    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","  )\n","  (up1): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","  (dec1): Sequential(\n","    (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","  )\n","  (final): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",")"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["ipt, lbl = next(iter(testloader))"],"metadata":{"id":"js8YV5E0QZZd","executionInfo":{"status":"ok","timestamp":1765479506197,"user_tz":300,"elapsed":113,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["pred = model(ipt)[\"recon\"]\n","save_img_tensors_as_grid(pred, nrows = 6, f=\"images/unet_recon_output\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ncUkSRrTHqj","executionInfo":{"status":"ok","timestamp":1765479557581,"user_tz":300,"elapsed":35,"user":{"displayName":"Cheng Qiu","userId":"04986819439057181062"}},"outputId":"2feab3f8-e820-405b-f639-3e0fe6e987f9"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":12}]}]}